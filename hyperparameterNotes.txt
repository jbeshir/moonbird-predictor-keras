MSE with various different hyperparameters with only the estimates as features

Assume by default:
- Working input scaling
- epochs=100
- padvalue=-1
- layer=SimpleRNN
- n_a=4
- dense_layers=1
- L1 regularisation: 0.0
- L2 regularisation: 0.0

RegLSTM refers to L1 and L2 regularisation only applied to the LSTM layer, not others.

MSE is for CV set; if train set is omitted, CV set performed better than it.


After switching the loss function to MSE proper, working masked sequential layer and scaling:

layer=LSTM 0.1632/cv 0.1713/train
layer=LSTM,dense_layers=2,L1=0.000003,L2=0.000003 0.1632/cv 0.1713/train - Almost identical performance to LSTM alone.
layer=LSTM,dense_layers=2,L1=0.0000003,L2=0.0000003 0.1634/cv 0.1714/train - Slightly higher bias.
layer=LSTM,dense_layers=2,L1=0.00003,L2=0.00003 0.1634/cv 0.1714/train - Slightly higher bias.
layer=LSTM,dense_layers=2,L1=0.0001,L2=0.0001 0.1634/cv 0.1715/train - Slightly higher bias.
layer=2xLSTM 0.1636/cv 0.1708/train - Slight training improvement but more overfitting.
layer=LSTM,dense_layers=2 0.1640/cv 0.1702/train - Training improvement but more overfitting.
layer=LSTM,dense_layers=2,L1=0.0003,L2=0.0003 0.1641/cv 0.1723/train - Slightly higher bias.
layer=LSTM,dense_layers=2,L1=0.001,L2=0.001 0.1653/cv 0.1734/train - Higher bias.
layer=2xSimpleRNN 0.1642/cv 0.1710/train
All default: 0.1644

After adding prediction timestamp feature (with above):

layer=LSTM 0.1637/cv and 0.1712/train - Looks like a slight training improvement but slightly more overfit.

After adding has comment feature (with above):

layer=LSTM 0.1636/cv and 0.1715/train - No improvement.

After adding prediction timestamp, has comment, and question length features (with above):

All default: 0.1641/cv and 0.1720/train - Very slight improvement if any.

After adding average wordvec of question feature (with above):

layer=LSTM 0.1754/cv 0.1531/train - Overfit, but major training improvement. Retry with regularisation?
layer=RegLSTM+L1=0.01,L2=0.02 0.1680/cv and 0.1758/train - Suffers from higher bias.
layer=RegLSTM+L1=0.003,L2=0.003 0.1647/cv and 0.1722/train - Slightly worse than without the feature, but much less overfit.
layer=RegLSTM+L1=0.001,L2=0.001 0.1644/cv and 0.1693/train - Slightly worse than without the feature, but much less overfit. Training improvement.
layer=RegLSTM+L1=0.0003,L2=0.0003 0.1669/cv and 0.1630/train - Regularisation reduced overfit, but fit is still worse, and it is still doing worse than without the feature.
layer=RegLSTM+L1=0.0001,L2=0.0001 0.17415/cv and 0.1543/train - Slight improvement from regularisation relatively to unregularised, but not much.



After working masked sequential layer and scaling:

layer=LSTM 0.1631
All default: 0.1644 (0.1640 previously seems to have been a data error?)
dense_layers=2 0.1640
layer=2xSimpleRNN: 0.1642 - We don't overfit anymore. Still don't get any improvements over a single RNN layer.


After adding prediction timestamp feature (with masked sequential layer and input scaling):

layer=LSTM 0.1633 - Not as good as LSTM without this feature. Harder to train?
All default: 0.1637 - No more overfit. Slight improvement?


After adding has comment feature (with masked sequential layer and input scaling):

layer=LSTM 0.1634 - Not as good as LSTM without this feature. Harder to train?
All default: 0.1639 - Very slight improvement?



After working masked input scaling:

All default: 0.1633



After working unmasked input scaling:

layer=GRU 0.1635
layer=LSTM 0.1636
dense_layers=2 0.1636
All default: 0.1637
n_a=2,dense_layers=4 0.1637
n_a=6 0.1643
dense_layers=4 0.1651
n_a=2,dense_layers=2 0.1661
n_a=2,layer=2xSimpleRNN: 0.1917
n_a=1 0.2457
layer=2xSimpleRNN: 0.273/cv vs 0.173/train - Overfit, with no reduction to bias.


After adding prediction timestamp feature (with unmasked input scaling):

All default: 0.3926/cv 0.3034/cv vs still 0.174/train - It becomes inconsistently overfit on due date.


After adding question length feature (with unmasked input scaling):

All default: 0.1643 - Doesn't seem to contribute a detectable amount of information.


After adding question avg wordvec feature (with unmasked input scaling):

All default: 0.1701 - Seems to worsen fit (although CV still doing better than train)


After adding has comment feature (with unmasked input scaling):

All default: 0.1717 - Seems to make it harder to train.
epochs=200: 0.2340/cv vs 0.1775/train - Apparently became overfit.



Before working input scaling, only prediction value as feature:

No input scaling 0.164,0.1650,0.1636
No input scaling,n_a=1 0.1672
No input scaling,n_a=2 0.1655
No input scaling,n_a=3 0.1649
No input scaling,n_a=5 0.164,0.1638
No input scaling,n_a=6 0.1643

No input scaling,layer=GRU 0.1653
No input scaling,layer=GRU,n_a=2 0.1642

No input scaling,layer=LSTM,n_a=2 0.1644