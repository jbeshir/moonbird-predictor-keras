MSE with various different hyperparameters with only the estimates as features

Assume by default:
- Working input scaling
- epochs=100
- padvalue=-1
- layer=SimpleRNN
- n_a=4
- dense_layers=1

MSE is for CV set; if train set is omitted, CV set performed better than it.

After working masked input scaling:

All default: 0.1633


After working unmasked input scaling:

layer=GRU 0.1635
layer=LSTM 0.1636
dense_layers=2 0.1636
All default: 0.1637
n_a=2,dense_layers=4 0.1637
n_a=6 0.1643
dense_layers=4 0.1651
n_a=2,dense_layers=2 0.1661
n_a=2,layer=2xSimpleRNN: 0.1917
n_a=1 0.2457
layer=2xSimpleRNN: 0.273/cv vs 0.173/train - Overfit, with no reduction to bias.


After adding prediction timestamp feature (with unmasked input scaling):

All default: 0.3926/cv 0.3034/cv vs still 0.174/train - It becomes inconsistently overfit on due date.


After adding question length feature (with unmasked input scaling):

All default: 0.1643 - Doesn't seem to contribute a detectable amount of information.


After adding question avg wordvec feature (with unmasked input scaling):

All default: 0.1701 - Seems to worsen fit (although CV still doing better than train)


After adding has comment feature (with unmasked input scaling):

All default: 0.1717 - Seems to make it harder to train.
epochs=200: 0.2340/cv vs 0.1775/train - Apparently became overfit.


Before working input scaling, only prediction value as feature:

No input scaling 0.164,0.1650,0.1636
No input scaling,n_a=1 0.1672
No input scaling,n_a=2 0.1655
No input scaling,n_a=3 0.1649
No input scaling,n_a=5 0.164,0.1638
No input scaling,n_a=6 0.1643

No input scaling,layer=GRU 0.1653
No input scaling,layer=GRU,n_a=2 0.1642

No input scaling,layer=LSTM,n_a=2 0.1644





